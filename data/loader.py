import streamlit as st
import pandas as pd
import os
from config import JSON_AVAILABLE
from .sample_data import create_sample_data

if JSON_AVAILABLE:
    import json

@st.cache_data
def load_nba_data(data_dir='nba_data'):
    """NBA ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰"""
    data = {}
    
    if not os.path.exists(data_dir):
        # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã§ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        return create_sample_data()
    
    file_mappings = {
        'per_game': 'nba_2025_per_game_stats.json',
        'advanced': 'nba_2025_advanced_stats.json',
        'play_by_play': 'nba_2025_play_by_play_stats.json',
        'team_salaries': 'nba_team_salaries_2025.json',
        'player_salaries': 'nba_player_salaries_2025.json'
    }
    
    files_loaded = 0
    
    # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆUIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã—ï¼‰
    for key, filename in file_mappings.items():
        filepath = os.path.join(data_dir, filename)
        
        try:
            if os.path.exists(filepath):
                df = load_json_file(filepath)
                
                if not df.empty:
                    df = convert_numeric_columns(df)
                    data[key] = df
                    files_loaded += 1
                else:
                    data[key] = pd.DataFrame()
            else:
                data[key] = pd.DataFrame()
                
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ã‚‚è¡¨ç¤ºã›ãšã€ç©ºã®DataFrameã‚’è¨­å®š
            data[key] = pd.DataFrame()
    
    if files_loaded == 0:
        # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã§ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        return create_sample_data()
    
    # ä½•ã‚‚è¡¨ç¤ºã›ãšã«çµæœã‚’è¿”ã™
    return data

def load_json_file(filepath):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã«å¤‰æ›"""
    if not JSON_AVAILABLE:
        raise ImportError("JSONãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
            
        if isinstance(json_data, list):
            df = pd.DataFrame(json_data)
        elif isinstance(json_data, dict):
            # è¾æ›¸ã®å ´åˆã€é©åˆ‡ã«DataFrameã«å¤‰æ›
            if 'data' in json_data:
                df = pd.DataFrame(json_data['data'])
            else:
                df = pd.DataFrame([json_data])
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„JSONå½¢å¼: {type(json_data)}")
        
        return df
        
    except json.JSONDecodeError as e:
        raise ValueError(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def convert_numeric_columns(df):
    """æ•°å€¤ã‚«ãƒ©ãƒ ã®å¤‰æ›"""
    # ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ ã‚’é™¤å¤–
    text_columns = ['Team', 'Tm', 'player_name', 'team', 'source', 'Player', 'name']
    
    for col in df.columns:
        if col not in text_columns:
            df[col] = pd.to_numeric(df[col], errors='ignore')
    
    return df

def validate_data_structure(data):
    """ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼"""
    validation_results = {}
    
    # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒã‚§ãƒƒã‚¯
    required_datasets = ['per_game', 'advanced']
    for dataset in required_datasets:
        if dataset in data and not data[dataset].empty:
            validation_results[dataset] = "âœ… OK"
        else:
            validation_results[dataset] = "âŒ Missing or Empty"
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒã‚§ãƒƒã‚¯
    optional_datasets = ['player_salaries', 'team_salaries', 'play_by_play']
    for dataset in optional_datasets:
        if dataset in data and not data[dataset].empty:
            validation_results[dataset] = "âœ… Available"
        else:
            validation_results[dataset] = "âš ï¸ Not Available"
    
    return validation_results

def get_data_summary(data):
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
    summary = {}
    
    for key, df in data.items():
        if not df.empty:
            summary[key] = {
                'records': len(df),
                'columns': len(df.columns),
                'memory_usage': df.memory_usage(deep=True).sum(),
                'null_values': df.isnull().sum().sum()
            }
        else:
            summary[key] = {
                'records': 0,
                'columns': 0,
                'memory_usage': 0,
                'null_values': 0
            }
    
    return summary

def display_data_validation_report(data):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
    
    validation_results = validate_data_structure(data)
    summary = get_data_summary(data)
    
    # æ¤œè¨¼çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    validation_df = pd.DataFrame([
        {
            'Dataset': dataset,
            'Status': status,
            'Records': summary.get(dataset, {}).get('records', 0),
            'Columns': summary.get(dataset, {}).get('columns', 0)
        }
        for dataset, status in validation_results.items()
    ])
    
    st.dataframe(validation_df, use_container_width=True)
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    total_memory = sum(info.get('memory_usage', 0) for info in summary.values())
    st.info(f"ğŸ’¾ ç·ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {total_memory / 1024 / 1024:.2f} MB")
    
    return validation_results

@st.cache_data
def load_external_data_source(source_url):
    """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰"""
    # å°†æ¥çš„ã«APIã‚„Webã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å ´åˆã®æº–å‚™
    st.info(f"ğŸŒ å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™: {source_url}")
    return create_sample_data()

def export_data_to_csv(data, output_dir='exported_data'):
    """ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    exported_files = []
    
    for key, df in data.items():
        if not df.empty:
            filepath = os.path.join(output_dir, f"{key}.csv")
            df.to_csv(filepath, index=False)
            exported_files.append(filepath)
    
    return exported_files